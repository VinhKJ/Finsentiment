"""Application entrypoint and data exporter.

This module starts the Flask application and also provides a helper utility to
export data generated by the backend to a JSON file.  Environments like Render
can execute this module to both start the API server and produce a snapshot of
the latest posts and stock information.
"""

import json
import os
from datetime import datetime

try:  # pragma: no cover - import for package or script execution
    from .app import app, reddit_fetcher, sentiment_analyzer, stock_data_fetcher
except ImportError:
    # When running as a script, "backend" isn't treated as a package.
    from app import app, reddit_fetcher, sentiment_analyzer, stock_data_fetcher


def generate_json_file(filename: str = "data.json") -> None:
    """Generate a JSON file containing posts and stock data.

    The function replicates the logic used by the API endpoints to gather
    Reddit posts (with sentiment analysis) and popular stock information.  The
    resulting structure is written to ``filename`` inside the backend directory
    so that other services can read the precomputed data without having to call
    the API.
    """

    # Fetch and analyse Reddit posts
    posts = reddit_fetcher.get_posts("wallstreetbets", "day", "hot", limit=25)
    for post in posts:
        text = f"{post['title']} {post['selftext']}"
        post["sentiment"] = sentiment_analyzer.analyze_text(text)
        created = post.get("created_utc")
        if isinstance(created, datetime):
            post["created_utc"] = created.isoformat()

    # Gather stock information
    popular_stocks = [
        "AAPL",
        "MSFT",
        "GOOG",
        "AMZN",
        "TSLA",
        "META",
        "NVDA",
        "SPY",
        "QQQ",
        "AMD",
    ]
    stocks = []
    for symbol in popular_stocks:
        company_info = stock_data_fetcher.get_stock_overview(symbol)
        price_data = stock_data_fetcher.get_daily_prices(symbol, days=1)
        latest_price = price_data[0]["close"] if price_data else None

        sentiment_data = reddit_fetcher.get_historical_sentiment(symbol, days=7)
        sentiments = [d.get("sentiment_avg", 0) for d in sentiment_data]
        avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0

        stocks.append(
            {
                "symbol": symbol,
                "name": company_info.get("name", f"{symbol} Inc."),
                "price": latest_price,
                "sector": company_info.get("sector", "Technology"),
                "sentiment": avg_sentiment,
            }
        )

    data = {"posts": posts, "stocks": stocks}

    # Ensure the file is written inside the backend directory
    output_path = os.path.join(os.path.dirname(__file__), filename)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)


if __name__ == "__main__":
    # Generate JSON snapshot for environments like Render that expect a file
    # output after running the backend code.
    generate_json_file()

    # Start the API server as before
    app.run(host="0.0.0.0", port=5000, debug=True)

